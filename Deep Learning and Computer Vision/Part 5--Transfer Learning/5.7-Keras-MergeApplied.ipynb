{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Merge Applied\n",
    "\n",
    "For complex models use the Functional API. Sequential model cannot handle merges, models with multiple inputs and outputs, models with shared layers.\n",
    "\n",
    "Reference: https://www.puzzlr.org/the-keras-functional-api-five-simple-examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, concatenate\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row = 1000\n",
    "x1 = np.random.randn(n_row)\n",
    "x2 = np.random.randn(n_row)\n",
    "x3 = np.random.randn(n_row)\n",
    "y_classifier = np.array([1 if (x1[i] + x2[i] + (x3[i])/3 + np.random.randn(1) > 1) else 0 for i in range(n_row)])\n",
    "y_cts = x1 + x2 + x3/3 + np.random.randn(n_row)\n",
    "dat = np.array([x1, x2, x3]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.scatter(dat[:,0],dat[:,1], c=y_classifier)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate indexes of test and train \n",
    "idx_list = np.linspace(0,999,num=1000)\n",
    "idx_test = np.random.choice(n_row, size = 200, replace=False)\n",
    "idx_train = np.delete(idx_list, idx_test).astype('int')\n",
    " \n",
    "# Split data into test and train\n",
    "dat_train = dat[idx_train,:]\n",
    "dat_test = dat[idx_test,:]\n",
    "\n",
    "y_classifier_train = y_classifier[idx_train]\n",
    "y_classifier_test = y_classifier[idx_test]\n",
    "y_cts_train = y_cts[idx_train]\n",
    "y_cts_test = y_cts[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model\n",
    "\n",
    "Build logistic regression using the Keras functional model. \n",
    "\n",
    "The input layer needs to have shape (p,) where p is the number of columns in your training matrix. In our case we have three columns (x_1, x_2, x_3) so we set the shape to (3,)\n",
    "\n",
    "The output layer needs to have the same number of dimensions as the number of neurons in the dense layer. In our case weâ€™re predicting a binary vector (0 or 1), which has 1 dimension, so our dense layer needs to have one neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with Functional API\n",
    "inputs = Input(shape=(3,))\n",
    "output = Dense(1, activation='sigmoid')(inputs)\n",
    "logistic_model = Model(inputs, output)\n",
    " \n",
    "# Compile the model \n",
    "logistic_model.compile(optimizer='sgd',\n",
    "                       loss = 'binary_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training data\n",
    "logistic_model.fit(x=dat_train, y=y_classifier_train, epochs = 500, verbose=0,\n",
    "                   validation_data = (dat_test, y_classifier_test))\n",
    "logistic_model.fit(x=dat_train, y=y_classifier_train, epochs = 1, verbose=1,\n",
    "                   validation_data = (dat_test, y_classifier_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(logistic_model,show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Model\n",
    "\n",
    "Below we train a neural network with a large number of hidden layers. We also add Dropout to the layers to reduce overfitting.\n",
    "\n",
    "It can be useful sometimes to use for loops and if statements when using the Functional API, particularly for complicated models.\n",
    "\n",
    "This model does about as well as the previous neural network. It could probably do better by tuning the hyperparameters, like the amount of dropout or the number of neural network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify how many hidden layers to add (min 1)\n",
    "n_layers = 5\n",
    " \n",
    "inputs = Input(shape=(3,))\n",
    "x = Dense(200, activation='relu')(inputs)\n",
    "x = Dropout(0.4)(x)\n",
    "for layer in range(n_layers - 1):\n",
    "    x = Dense(200, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "deep_n_net = Model(inputs, output)\n",
    " \n",
    "deep_n_net.compile(optimizer = 'adam', loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "deep_n_net.fit(dat_train, y_classifier_train, epochs = 50, verbose=0,\n",
    "validation_data = (dat_test, y_classifier_test))\n",
    "deep_n_net.fit(dat_train, y_classifier_train, epochs = 1, verbose=1,\n",
    "validation_data = (dat_test, y_classifier_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_n_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(deep_n_net,show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neural Network + Metadata\n",
    "\n",
    "One use case for the Functional API is where you have multiple data sources that you want to pull together into one model.\n",
    "\n",
    "For example, if your task is image classification you could use the Sequential model to build a convolutional neural network that would run over the images. If you decide to use the Functional API instead of the Sequential model, you can also include metadata of your image into your model: perhaps its size, date created, or its tagged location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_1 = y_classifier + np.random.gumbel(scale = 0.6, size = n_row)\n",
    "metadata_2 = y_classifier - np.random.laplace(scale = 0.5, size = n_row)\n",
    "metadata = np.array([metadata_1,metadata_2]).T\n",
    " \n",
    "# Create training and test set\n",
    "metadata_train = metadata[idx_train,:]\n",
    "metadata_test = metadata[idx_test,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dat = Input(shape=(3,)) # for the three columns of dat_train\n",
    "n_net_layer = Dense(50, activation='relu') # first dense layer\n",
    "x1 = n_net_layer(input_dat)\n",
    "x1 = Dropout(0.5)(x1)\n",
    " \n",
    "input_metadata = Input(shape=(2,))\n",
    "x2 = Dense(25, activation= 'relu')(input_metadata)\n",
    "x2 = Dropout(0.3)(x2)\n",
    " \n",
    "con = concatenate(inputs = [x1,x2] ) # merge in metadata\n",
    "x3 = Dense(50)(con)\n",
    "x3 = Dropout(0.3)(x3)\n",
    "output = Dense(1, activation='sigmoid')(x3)\n",
    "meta_n_net = Model(inputs=[input_dat, input_metadata], outputs=output)\n",
    " \n",
    "meta_n_net.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(meta_n_net,show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_n_net.fit(x=[dat_train, metadata_train], y=y_classifier_train, epochs=50, verbose=0,\n",
    "validation_data=([dat_test, metadata_test], y_classifier_test))\n",
    "meta_n_net.fit(x=[dat_train, metadata_train], y=y_classifier_train, epochs=1, verbose=1,\n",
    "validation_data=([dat_test, metadata_test], y_classifier_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
